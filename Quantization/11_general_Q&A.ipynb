{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization Methods:\n",
    "- ### LLM.int8: 8-bit integer quantization with linear layer model. [paper](https://arxiv.org/abs/2208.07339)\n",
    "![llm](./img/llm-int8.png)\n",
    "- ### SmoothQuant: W8A8 per channel quantization with smoothness regularization. [paper](https://arxiv.org/abs/2211.10438)\n",
    "\n",
    "![sq1](./img/sq1.png)\n",
    "\n",
    "![sq2](./img/sq2.png)\n",
    "\n",
    "- ### QLora: 8-bit integer quantization with Lora compression. [paper](https://arxiv.org/abs/2305.14314)\n",
    " AWQ: 8-bit integer quantization with adaptive weight quantization. [paper](https://arxiv.org/abs/2004.09602)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
